{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ce48f6-5132-4327-8291-1f0f35e94899",
   "metadata": {},
   "source": [
    "# Sales forecasting\n",
    "### ... with a lot less historical data than we would prefer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efff939-4c29-48ec-ba86-99a429a82eb3",
   "metadata": {},
   "source": [
    "This notebook contains my solution to a hypothetical business problem relating to a company's sales data, the source of which is a truncated version of a data set I downloaded off Kaggle. The data is a few years old now, so in the context of this task it is currently early 2020 and we have no reason to suspect that the remainder of the year will be notably dissimilar to the last couple of years.\n",
    "\n",
    "In addition to this notebook file, there are two other files in the directory:\n",
    "- sales.csv (The historical sales data, provided in monthly intervals)\n",
    "- requirements.txt (Python dependencies)\n",
    "\n",
    "Please note that I have manually inserted images of figures in some of the cells so that they render on GitHub. To generate the figures programmatically you will either need to save a local copy or use nbviewer and execute the cell above the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a71438-1f2d-4f27-96cf-0b771fc99f29",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "* [Business Problem](#business-problem)\n",
    "* [The Solution](#solution)\n",
    "    * [Install dependencies](#install-dependencies)\n",
    "    * [Import modules](#import-modules)\n",
    "    * [Characteristics of the time series](#characteristics-time-series)\n",
    "    * [Model building](#model-building)\n",
    "        * [Random Walk](#random-walk)\n",
    "        * [ETS](#ets)\n",
    "        * [ARIMA](#arima)\n",
    "        * [Regression](#regression)\n",
    "    * [Comparing each model's 12-month forecast](#comparing-model-forecasts)\n",
    "    * [Model cross validation](#model-cross-validation)\n",
    "    * [Evaluation of the models](#evaluation-models)\n",
    "* [Conclusions](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689dc22b-6d8b-4ee3-a3d4-8f8ca44a2f6d",
   "metadata": {},
   "source": [
    "## <a id=\"business-problem\">Business Problem</a>\n",
    "***\n",
    "\n",
    "A retail business launched a new product in the final quarter of 2017, which has historically been their most profitable time of the year due to increased consumer spending leading up to Christmas. The new product has been selling well and appears to have been gaining momentum in the market over the past 2 years. The business would now like to know how well the product is expected to sell over the coming 12 months.\n",
    "\n",
    "The product was incrementally soft launched over a number of weeks and as a result stable data is only available from January 2018 up to February 2020 (last month)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61a585-fdac-4ca6-9ce4-c3dc5d6050f8",
   "metadata": {},
   "source": [
    "## <a id=\"solution\">The Solution</a>\n",
    "***\n",
    "### <a id=\"install-dependencies\">Install dependencies</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36e42e-c289-4ca9-aae3-20557ff447f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb26759-b6a0-441b-827b-057541efa34d",
   "metadata": {},
   "source": [
    "### <a id=\"import-modules\">Import modules</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3077c1b0-acdf-478a-acb8-730c226eab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsforecast.models import SeasonalNaive\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Disable scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Altair custom theme\n",
    "@alt.theme.register('theme', enable = True)\n",
    "def theme():\n",
    "    return alt.theme.ThemeConfig({\n",
    "        'background': '#FFFFFF',\n",
    "        'config': {\n",
    "            'axis': {'domainOpacity': 0, 'gridColor': '#ECECEC', 'labelFontSize': 10, 'labelPadding': 18, 'tickColor': '#ECECEC', 'tickSize': 8},\n",
    "            'legend': {'clipHeight': 16, 'symbolStrokeWidth': 10, 'labelFontSize': 12},\n",
    "            'line': {'size': 4},\n",
    "            'mark': {'color': '#000000'},\n",
    "            'point': {'fill': '#BABABA', 'size': 150},\n",
    "            'range': {'category': {'scheme': 'category10'}}\n",
    "        },\n",
    "        'height': 400,\n",
    "        'width': 800\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f3b6e-3107-4762-9938-66ce205faed9",
   "metadata": {},
   "source": [
    "### <a id=\"characteristics-time-series\">Characteristics of the time series</a>\n",
    "\n",
    "The time series contains aggregated monthly sales over a 26-month period from Jan '18 through to Feb '20. The summary statistics and figure displaying the sales over time reveal a number of characteristics:\n",
    "- There have been an average of 450,000 sales per month.\n",
    "- The standard deviation is 240,000 sales per month, while the IQR is only 150,000; indicating the distribution skews to the right.\n",
    "- There was a sharp increase in sales during November and December in both years, likely attributable to the Christmas spending mentioned above.\n",
    "- There appears to be a slightly upward trend in sales over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7c81a58f-0a15-4f8d-b554-df9f83707843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sales</th>\n",
       "      <td>26.000</td>\n",
       "      <td>449354.231</td>\n",
       "      <td>238314.771</td>\n",
       "      <td>236985.000</td>\n",
       "      <td>310489.000</td>\n",
       "      <td>368518.000</td>\n",
       "      <td>461642.500</td>\n",
       "      <td>1144687.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count       mean        std        min        25%        50%  \\\n",
       "Sales 26.000 449354.231 238314.771 236985.000 310489.000 368518.000   \n",
       "\n",
       "             75%         max  \n",
       "Sales 461642.500 1144687.000  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.read_csv('sales.csv')\n",
    "ts['Date'] = pd.to_datetime(ts['Date'])\n",
    "ts.set_index('Date', inplace = True)\n",
    "\n",
    "ts.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf9c6d-6cec-46f3-a1ff-600af145ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate trend line \n",
    "trend_index = np.arange(0, len(ts)).reshape(-1, 1)\n",
    "lm = LinearRegression().fit(trend_index, ts['Sales'].to_numpy())\n",
    "trend_line = pd.DataFrame({'Date': ts.reset_index()['Date'], 'Sales': lm.predict(trend_index)})\n",
    "\n",
    "alt.Chart(ts.reset_index()).mark_line().encode(\n",
    "    x = alt.X('Date', timeUnit = 'yearmonth'),\n",
    "    y = 'Sales'\n",
    ") + alt.Chart(trend_line).mark_line(color = '#F4A460').encode(\n",
    "    x = alt.X('Date', timeUnit = 'yearmonth'),\n",
    "    y = 'Sales'\n",
    ").properties(\n",
    "    title = \"Monthly sales from Jan '18 to Feb '20 with linear trend\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b4561-db31-4cf8-a8d6-a5621c724ce5",
   "metadata": {},
   "source": [
    "<img src=\"img/sales-with-trend.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99733c68-a5c1-496c-a50c-c21e2326d3ad",
   "metadata": {},
   "source": [
    "### <a id=\"model-building\">Model building</a>\n",
    "\n",
    "Due to the characteristics of the time series we will test out a few different models to find the best fit. The proposed models are:\n",
    "- Random Walk\n",
    "- ETS (Error Trend Seasonality)\n",
    "- ARIMA (Autoregressive Integrated Moving Average)\n",
    "- Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f510ad-0471-4976-ba7f-dcb34e42058e",
   "metadata": {},
   "source": [
    "#### <a id=\"random-walk\">Random Walk</a>\n",
    "\n",
    "A monthly random walk model is a good place to start; each forecast will be equal to the number of sales in the same month of the previous year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4478f646-9b82-44fe-aafa-850ef4c61056",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_walk_mdl = SeasonalNaive(season_length = 12)\n",
    "random_walk_mdl.fit(ts['Sales'])\n",
    "random_walk_pred = random_walk_mdl.predict(h = 12)['mean']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aefa05e-8bdb-440c-8ebd-a808cfc36ab5",
   "metadata": {},
   "source": [
    "#### <a id=\"ets\">ETS</a>\n",
    "\n",
    "The upward trend and seasonal pattern make ETS an appealing option. The end of year spike in 2019 looked sharper than the previous year, so the seasonal component was modelled as multiplicative in an attempt to capture the increasing variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a353c5a-eb8d-4f52-88ae-342950e00cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_mdl = ETSModel(ts['Sales'], trend = 'add', seasonal = 'mul', freq = 'ME')\n",
    "ets_mdl_fit = ets_mdl.fit(disp = False)\n",
    "ets_pred = ets_mdl_fit.forecast(steps = 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b723b48-ee52-455d-9aca-28fec50dfaa8",
   "metadata": {},
   "source": [
    "#### <a id=\"arima\">ARIMA</a>\n",
    "\n",
    "If we're building an ETS model then we may as well also include an ARIMA model. To help the automatic model selection process handle the small sample size, we increased the traditional alpha level of 0.05 up to a more casual 0.2. There isn't enough data to fit a seasonal component.\n",
    "\n",
    "The best fitting model selected was (0, 2, 3), which is conceptually similar to a moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fe841-3aff-4409-885e-aafdfc4c0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_mdl = auto_arima(ts['Sales'], stepwise = False, alpha = 0.2)\n",
    "arima_pred = arima_mdl.predict(12)\n",
    "arima_mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece3fa5-1f91-4769-aa3d-80bcaf7ae45b",
   "metadata": {},
   "source": [
    "#### <a id=\"regression\">Regression</a>\n",
    "\n",
    "With some minor alterations to our data we can also fit a regression model. We need to expand the data into a tabular format and use the months and trend as features to build the model. The monthly sales have been fit using a logarithmic scale to reduce the impact of the distribution's skewing on the forecasted values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b6b55bdd-78f9-4357-b7e9-10cfa4cf7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features_from_date_series(s, trend_offset = 0):\n",
    "\n",
    "    s.name = 'Date'\n",
    "\n",
    "    # Generate dummy dates in case the data passed into the function doesn't contain a full 12 months\n",
    "    # All 12 months need to be created as columns\n",
    "    dummy_dates = pd.Series(pd.date_range(start = '1900-01-31', freq = 'ME', periods = 12), name = 'Date')\n",
    "    \n",
    "    df = pd.DataFrame(pd.concat([s, dummy_dates], ignore_index = True))\n",
    "\n",
    "    # Encode month names as dummy variables\n",
    "    df['Month'] = df['Date'].dt.month_name()\n",
    "    df = pd.get_dummies(df, columns = ['Month'], dtype = 'int')\n",
    "\n",
    "    # Use incrementing index for trend feature\n",
    "    df = df.reset_index()\n",
    "    df.rename(columns = {'index': 'Trend'}, inplace = True)\n",
    "    df['Trend'] += trend_offset # Offset is needed for predictions (offset = number of observations used in model training)\n",
    "\n",
    "    # Remove dummy dates\n",
    "    df = df[~df['Date'].isin(dummy_dates)]\n",
    "\n",
    "    # Remove January column to avoid dummy variable multicollinearity issue\n",
    "    df.drop(columns = ['Month_January'], inplace = True)\n",
    "\n",
    "    df.set_index('Date', inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_train = build_features_from_date_series(ts.reset_index()['Date'])\n",
    "\n",
    "regression_mdl = LinearRegression()\n",
    "regression_mdl.fit(X_train.to_numpy(), np.log(ts['Sales']).to_numpy())\n",
    "\n",
    "# Generate dates for the next 12 monthly forecast horizons\n",
    "test_horizon_dates = pd.Series(pd.date_range(start = X_train.index.max() + pd.DateOffset(months = 1), freq = 'ME', periods = 12))\n",
    "\n",
    "X_test = build_features_from_date_series(test_horizon_dates, trend_offset = len(X_train))\n",
    "\n",
    "regression_pred = np.exp(regression_mdl.predict(X_test.to_numpy())) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7571c37-8cd7-4733-92da-eaa26ead6c6c",
   "metadata": {},
   "source": [
    "### <a id=\"comparing-model-forecasts\">Comparing each model's 12-month forecast</a>\n",
    "\n",
    "After calculating each model's forecast for the next 12-months we can see they have captured different characteristics of the time series:\n",
    "- The ETS, ARIMA and regression models all forecasted an upward trend.\n",
    "- The random walk, ETS and regression models all forecasted the end of year seasonality.\n",
    "- The ETS and regression models forecasted the increasing seasonality at the end of the year.\n",
    "\n",
    "The forecasts from the ARIMA model don't appear to be very sensible; they began at a point that was highly influenced by the end of year seasonality and the subsequent forecasts continued to rise from there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1e3086-f9c7-433b-a0a7-13c40a751413",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_12month_pred = {\n",
    "    'Random Walk': list(random_walk_pred),\n",
    "    'ETS': list(ets_pred),\n",
    "    'ARIMA': list(arima_pred),\n",
    "    'Regression': list(regression_pred)\n",
    "}\n",
    "\n",
    "mdl_12month_pred = pd.DataFrame(mdl_12month_pred, index = test_horizon_dates)\n",
    "mdl_12month_pred_long = pd.melt(\n",
    "    mdl_12month_pred.reset_index(),\n",
    "    id_vars = 'Date',\n",
    "    value_vars = mdl_12month_pred.columns,\n",
    "    var_name = 'Model',\n",
    "    value_name = 'Sales'\n",
    ").set_index('Date')\n",
    "\n",
    "alt.Chart(ts.reset_index()).mark_line().encode(\n",
    "    x = alt.X('Date', timeUnit = 'yearmonth'),\n",
    "    y = 'Sales'\n",
    ") + alt.Chart(mdl_12month_pred_long.reset_index()).mark_line().encode(\n",
    "    x = alt.X('Date', timeUnit = 'yearmonth'),\n",
    "    y = 'Sales',\n",
    "    color = 'Model'\n",
    ").properties(\n",
    "    title = \"Actual sales with 12-month forecast for each proposed model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ddcfd-69ef-4306-afd4-26c3cd6b8f56",
   "metadata": {},
   "source": [
    "<img src=\"img/sales-with-12m-forecast.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5acdb92-aef1-4479-893d-ee90abbb3a2f",
   "metadata": {},
   "source": [
    "### <a id=\"model-cross-validation\">Model cross validation</a>\n",
    "\n",
    "ETS models with a seasonal component require at least two years of data for model fitting, so the ETS model could not be validated. The forecasts produced by the ARIMA model also didn't seem very realistic so the ARIMA model was also excluded. This left the random walk and the regression models.\n",
    "\n",
    "The chosen cross validation procedure is conceptually similar to K-Fold cross validation, while being more suitable for time series data. The train/test split for each fold has been outlined in the figure below. The grey dots indicate the months used for training, and the orange dots indicate test months. The testing was performed on the second forecast horizon (a gap of 1-month was left between training and testing for extra confidence in the training coefficients of the trend line). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "923238fc-d354-4aaa-aa96-fc4dc6745cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_cv_train_dates = []\n",
    "mdl_cv_pred_dates = []\n",
    "mdl_cv_pred = {'Random Walk': [], 'Regression': []}\n",
    "\n",
    "# Conduct cross validation\n",
    "# Train random walk and regression models and store the forecast for the test set across 12 splits\n",
    "# At each split the training set grows by 1 month and testing is always performed on a single month\n",
    "# The test set is the month following the month that was tested in the previous split\n",
    "\n",
    "test_horizon = 2 # Number of steps ahead the validation forecast horizon will be\n",
    "folds = TimeSeriesSplit(n_splits = 12, test_size = 1, gap = test_horizon - 1)\n",
    "for (i, j) in folds.split(ts):\n",
    "    ts_cv = ts.iloc[i]\n",
    "    horizon_date = ts.iloc[j].index\n",
    "\n",
    "    # Random Walk\n",
    "    random_walk_mdl_cv = SeasonalNaive(season_length = 12)\n",
    "    random_walk_mdl_cv.fit(ts_cv['Sales'])\n",
    "    random_walk_pred_cv = random_walk_mdl_cv.predict(h = test_horizon)['mean'][-1] # Only need the last prediction\n",
    "\n",
    "    # Regression\n",
    "    X_train_cv = build_features_from_date_series(ts_cv.reset_index()['Date'])\n",
    "    regression_mdl_cv = LinearRegression()\n",
    "    regression_mdl_cv.fit(X_train_cv.to_numpy(), np.log(ts_cv['Sales']).to_numpy())\n",
    "    X_test_cv = build_features_from_date_series(pd.Series(horizon_date), trend_offset = len(X_train_cv))\n",
    "    regression_pred_cv = np.exp(regression_mdl_cv.predict(X_test_cv.to_numpy())[0])\n",
    "\n",
    "    mdl_cv_pred_dates.append(pd.to_datetime(horizon_date.date[0]))\n",
    "    mdl_cv_pred['Random Walk'].append(random_walk_pred_cv)\n",
    "    mdl_cv_pred['Regression'].append(regression_pred_cv)\n",
    "\n",
    "    mdl_cv_train_dates.append(list(ts_cv.reset_index()['Date']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb59fc0-46fe-4649-90e9-18eb0c8a9b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_cv_train_summary = pd.DataFrame()\n",
    "mdl_cv_test_summary = pd.DataFrame()\n",
    "\n",
    "for i, j in enumerate(mdl_cv_train_dates):\n",
    "    fold_train_dates = pd.DataFrame({'Fold Number': f\"{i + 1}\", 'Date': j})\n",
    "    mdl_cv_train_summary = pd.concat([mdl_cv_train_summary, fold_train_dates])\n",
    "\n",
    "    fold_test_dates = pd.DataFrame({'Fold Number': f\"{i + 1}\", 'Date': [mdl_cv_pred_dates[i]]})\n",
    "    mdl_cv_test_summary = pd.concat([mdl_cv_test_summary, fold_test_dates])\n",
    "\n",
    "# Custom sorting for fold numbers on graph\n",
    "fold_sort_order = [f\"{i + 1}\" for i in range(12)]\n",
    "\n",
    "alt.Chart(mdl_cv_train_summary).mark_point().encode(\n",
    "    x = alt.X('Date', timeUnit = 'yearmonth'),\n",
    "    y = alt.Y('Fold Number', sort = fold_sort_order)\n",
    ") + alt.Chart(mdl_cv_test_summary).mark_point(fill = '#FF9933').encode(\n",
    "    x = alt.X('Date', timeUnit = 'yearmonth'),\n",
    "    y = alt.Y('Fold Number', sort = fold_sort_order)\n",
    ").properties(\n",
    "    title = 'An outline of the cross validation procedure (grey = train, orange = test)'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d1ed5-97d3-49c9-9486-9f095312a3ab",
   "metadata": {},
   "source": [
    "<img src=\"img/cv-procedure.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294f812-e419-43c8-b1ff-05089a18af94",
   "metadata": {},
   "source": [
    "### <a id=\"evaluation-models\">Evaluation of the models</a>\n",
    "\n",
    "The figure below outlines the deviation of each model's forecasts from the actual number of sales. The regression forecasts are higher due to the inclusion of the trend line. Both models underpredicted the end of year seasonality, but the forecasts from the regression model were a lot closer to the true values. The forecasts seem to get more unstable over time, however our sample only contains 26 data points so any further optimisation may lead to overfitting.\n",
    "\n",
    "The table compares each model's performance; where the regression error measured lower across MSE, RMSE, MAE and MAPE. Using the RMSE as a guideline, the average forecast deviates +/- 97,000 from the actual number of sales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd84ba-365b-43ca-8194-a32795aa47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the model error\n",
    "mdl_cv_pred = pd.DataFrame(mdl_cv_pred, index = mdl_cv_pred_dates)\n",
    "mdl_cv_true_values = mdl_cv_pred.merge(ts, how = 'inner', left_index = True, right_index = True)['Sales']\n",
    "\n",
    "mdl_cv_pred_error = mdl_cv_pred.sub(mdl_cv_true_values, axis = 0)\n",
    "mdl_cv_pred_error.index.name = 'Date'\n",
    "\n",
    "mdl_cv_pred_error = pd.melt(\n",
    "    mdl_cv_pred_error.reset_index(),\n",
    "    id_vars = 'Date',\n",
    "    value_vars = mdl_cv_pred_error.columns,\n",
    "    var_name = 'Model',\n",
    "    value_name = 'Error'\n",
    ")\n",
    "\n",
    "mdl_cv_pred_error['Date'] = pd.to_datetime(mdl_cv_pred_error['Date'])\n",
    "\n",
    "# Dashed line at 0\n",
    "mdl_line = pd.DataFrame({'Date': mdl_cv_pred_error['Date'].unique(), 'Error': 0})\n",
    "\n",
    "alt.Chart(mdl_line).mark_line(color = '#808080', strokeDash = [10, 10]).encode(\n",
    "    x = alt.X('Date', timeUnit = 'yearmonth'),\n",
    "    y = 'Error'\n",
    ") + alt.Chart(mdl_cv_pred_error).mark_line().encode(\n",
    "    x = alt.X('Date', timeUnit = 'yearmonth'),\n",
    "    y = 'Error',\n",
    "    color = 'Model'\n",
    ").properties(\n",
    "    title = \"Model error across the testing periods\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd0a4f-77f0-4194-b7c8-82f7fd34a470",
   "metadata": {},
   "source": [
    "<img src=\"img/model-error.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "98947138-d2e7-40d7-b04f-ccccd31d6b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Walk</th>\n",
       "      <td>15317587263.083</td>\n",
       "      <td>123764.241</td>\n",
       "      <td>101188.917</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regression</th>\n",
       "      <td>9411505355.093</td>\n",
       "      <td>97012.913</td>\n",
       "      <td>75794.299</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MSE       RMSE        MAE  MAPE\n",
       "Random Walk 15317587263.083 123764.241 101188.917 0.192\n",
       "Regression   9411505355.093  97012.913  75794.299 0.153"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_names = list(mdl_cv_pred.columns)\n",
    "mdl_cv_eval_metrics = {'MSE': [], 'RMSE': [], 'MAE': [], 'MAPE': []}\n",
    "\n",
    "# Calculate evaluation metrics for each model\n",
    "for i in mdl_names:\n",
    "    mse = mean_squared_error(mdl_cv_true_values, mdl_cv_pred[i])\n",
    "    rmse = root_mean_squared_error(mdl_cv_true_values, mdl_cv_pred[i])\n",
    "    mae = mean_absolute_error(mdl_cv_true_values, mdl_cv_pred[i])\n",
    "    mape = mean_absolute_percentage_error(mdl_cv_true_values, mdl_cv_pred[i])\n",
    "\n",
    "    mdl_cv_eval_metrics['MSE'].append(mse)\n",
    "    mdl_cv_eval_metrics['RMSE'].append(rmse)\n",
    "    mdl_cv_eval_metrics['MAE'].append(mae)\n",
    "    mdl_cv_eval_metrics['MAPE'].append(mape)\n",
    "\n",
    "mdl_cv_eval_summary = pd.DataFrame(mdl_cv_eval_metrics, index = mdl_names)\n",
    "mdl_cv_eval_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a46b25a-2a42-4694-b313-515720f3a732",
   "metadata": {},
   "source": [
    "## <a id=\"conclusions\">Conclusions</a>\n",
    "***\n",
    "\n",
    "The regression model performed the strongest through our cross validation procedure, and as a result is our preferred model. The 12-month forecast has been included below.\n",
    "\n",
    "It is strongly recommended that we repeat this activity again in 12 months time. At that point there will be enough data for the ETS model to be validated and there will hopefully be enough data to detect a more suitable ARIMA model, ideally one with a seasonal component. This additional year of data would also assist us in better understand the time series through proper analysis of the decomposition of seasonality, trend and ACF/PACF plots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b08d2d3a-ea80-4bc4-a4af-9ba79fcf1bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2020-03-31    463990.494\n",
       "2020-04-30    366756.362\n",
       "2020-05-31    392122.094\n",
       "2020-06-30    503815.525\n",
       "2020-07-31    434125.224\n",
       "2020-08-31    480966.830\n",
       "2020-09-30    550936.342\n",
       "2020-10-31    694149.104\n",
       "2020-11-30   1351735.847\n",
       "2020-12-31   1183601.354\n",
       "2021-01-31    440200.823\n",
       "2021-02-28    531754.455\n",
       "Name: Regression, dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_12month_pred['Regression']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
